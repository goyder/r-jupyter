{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference\n",
    "\n",
    "*A quick note - you can find LaTeX symbols [here](https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols#Set_and.2For_logic_notation).*\n",
    "\n",
    "## What is it?\n",
    "\n",
    "In brief, it's the process of generating conclusions about a population from a noisy sample. We'll collect *data* on a *population*, forming a *sample*.\n",
    "\n",
    "(Note there are a couple of key words here - *population*, and *sample*.)\n",
    "\n",
    "There are two broad schools - Bayesian, and frequentists.\n",
    "\n",
    "### I'm confused. Can you give me an example?\n",
    "\n",
    "Say we want to understand the mean height of all the male adults in Australia. Our *estimand* is therefore \"the mean height of all male adults in Australia\".\n",
    "\n",
    "We're probably not actually going to go and collect the height of this entire population (i.e. every male adult in Australia). Instead, we'll *estimate* the mean by taking a *sample* of, say, 100 male adults in Australia. We can then use this to develop an *estimator* - i.e. some kind of probabilistic model - that will allow us to *estimate* the *estimand*. \n",
    "\n",
    "In this process, we've taken a *sample* and linked it to a *population*.\n",
    "\n",
    "*[The above largely draws from this post.](https://www.quora.com/What-is-an-estimator-and-an-estimands-in-statistical-models-Why-this-is-important)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic rules of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability that nothing occurs is 0.\n",
    "* The probability that something occurs is 1.\n",
    "* The probability of something is 1 minus the probability that the opposite occurs.\n",
    "* The probability of at least one of two (or more) mutually exclusive events is the sum of their respective probabilities.\n",
    "* If an event A implies the occurence of event B, then the probability of A occurring is less than the probability that B occurs.\n",
    "* For any two events the probability that at least one occurs is the sum of their probabilities minus their intersection, i.e. $$P(A\\cup B) = P(A) + P(B) - P(A\\cap B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional probabilities\n",
    "\n",
    "Conditional probabilty is \"the measure of the probability of an event [...] given that [...] another event has occurred.\"\n",
    "\n",
    "We can define this as $P(A|B) = \\dfrac{P(A\\cap B)}{P(B)}$. In other words, the probability of event $A$ occurring *given* that event $B$ has occurred is equal to the intersection of events $A$ and $B$ divided by the probability of event $B$ occurring. This sounds really complex, but it is actually incredibly intuitive if you draw this out.\n",
    "\n",
    "*[Obligatory Wikipedia link.](https://en.wikipedia.org/wiki/Conditional_probability)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' theorem\n",
    "\n",
    "*Sometimes known as Bayes' law or Bayes' rule~~, or Bae's theorem if you really love Bayes~~*.\n",
    "\n",
    "Building on this, we can build it into Bayes' theorem. \n",
    "\n",
    "The most straightforward expression is: $P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$. The key thing here is that we can known swap $P(A|B)$ and $P(B|A)$.\n",
    "\n",
    "*[Obligatory Wikipedia link.](https://en.wikipedia.org/wiki/Bayes%27_theorem)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A classic example: diagnostic tests\n",
    "\n",
    "Let $+$ and $-$ be the events that the result of a diagnostic test is positive or negative.\n",
    "\n",
    "Let $D$ and $D^C$ be the event that the subject of the test does or does not have the disease being tested for.\n",
    "\n",
    "Therefore, $sensitivity = P(+|D)$ and $specificity = P(- | D^C)$. Both of these values should be high.\n",
    "\n",
    "Conversely, $\\text{positive predictive value} = P(D|+)$ and $\\text{negative predictive value} = P(D^C|-)$.\n",
    "\n",
    "#### Working back and forth\n",
    "\n",
    "So, if we have a situation where a test has a sensitivity of 99.7% and a specificity of 98.5%, this is on the surface a pretty good test.\n",
    "\n",
    "But consider there is a population with a 0.1% prevalence of said disease.\n",
    "\n",
    "What is the positive predictive value?\n",
    "\n",
    "We can test this by applying Bayes' Theorem - we are swapping the conditions. \n",
    "\n",
    "$P(D|+) = \\dfrac{P(+|D)P(D)}{P(+|D)P(D) + P(+|D^C)P(D^C)} = \\dfrac{0.997\\times 0.001}{0.997\\times 0.001 + 0.015\\times 0.999} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06238268051558003\n"
     ]
    }
   ],
   "source": [
    "pos_predictive_value = (0.997*0.001)/(0.997*0.001 + 0.015*0.999)\n",
    "print(pos_predictive_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore a positive test result only provides a 6.2% probability that the person actually has the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this idea further and explore the concept of a $\\text{likelihood ratio}$. The LR is a ratio of the probability that a test result is correct *versus* the probability that that test result is incorrect. It can be calculated for positive and negative cases. In this instance, $LR+ = \\dfrac{sensitivity}{1-specificity}$, and $LR- = \\dfrac{1-sensitivity}{specificity}$. \n",
    "\n",
    "This is typically used to generate *post-test odds* by the following formula:\n",
    "\n",
    "$\\dfrac{P(D|+)}{P(D^C|+)} = \\dfrac{P(D)}{P(D^C)} \\times LR+$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example - pregnancy tests\n",
    "\n",
    "A [web site](www.medicine.ox.ac.uk/bandolier/band64/b64-7.html) for home pregnancy tests cites the following: “When the subjects using the test were women who collected and tested their own samples, the overall sensitivity was 75%. Specificity was also low, in the range 52% to 75%.” Assume the lower value for the specificity. Suppose a subject has a positive test and that 30% of women taking pregnancy tests are actually pregnant. What number is closest to the probability of pregnancy given the positive test?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = 0.52\n",
    "sensitivity = 0.75\n",
    "p_pregnant = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above: $$P(D|+) = \\dfrac{P(+|D)P(D)}{P(+|D)P(D) + P(+|D^C)P(D^C)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pregnant_g_pos = (sensitivity*p_pregnant) / (sensitivity*p_pregnant + (1-specificity)*(1-p_pregnant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40106951871657753"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pregnant_g_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "*[Obligatory Wikipedia link.](https://en.wikipedia.org/wiki/Probability_distribution)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value\n",
    "\n",
    "For a given distribution, the 'expected value' can be intuitively described as the long-run average value of repetitions of the experiment it represents. This is more commonly referred as the *mean* or *first moment* but may also be referred to as *expectation* or *mathematical expectation*.\n",
    "\n",
    "#### Discrete values\n",
    "\n",
    "For a discrete value, it's just the combination of the values and their probabilities, i.e. $$E[X] = \\sum_{x} xp(x)$$\n",
    "\n",
    "#### Continuous values\n",
    "\n",
    "For a continuous value, it's similiar - an integration along the **cumulative distribution function**, i.e. $$E[X] = \\int xF(x)dx$$.\n",
    "\n",
    "#### Expected values in the context of inference\n",
    "\n",
    "Consider the following:\n",
    "* The population mean is the center of mass of a population.\n",
    "* The sample mean is the center of mass of the observed data - i.e. of the samples we took.\n",
    "* The sample mean is an estimate of the population mean. (We'll use our sample to *infer* something about the population.)\n",
    "* The sample mean is unbiased.\n",
    "* The more data that goes into the sample mean, the concentrated its density/mass function is around the population mean.\n",
    "\n",
    "*[Obligatory Wikipedia link.](https://en.wikipedia.org/wiki/Expected_value)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Distributions\n",
    "\n",
    "Continous values can take any outcome in a continuum. \n",
    "\n",
    "A useful introduction to these concepts can be found [here](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability density function\n",
    "\n",
    "A PDF is a function associated with a continuous random variable.\n",
    "\n",
    "To be a valid PDF, a function $p$, must:\n",
    "* Always be $\\geq 0$;\n",
    "* Have the total area under the function $= 1$.\n",
    "\n",
    "Hence, areas under PDFs correspond to probabilities for that random variable.\n",
    "\n",
    "Examples of probability densities functions include:\n",
    "* The [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution).\n",
    "\n",
    "\n",
    "#### Useful references\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)\">Wikipedia link.</a>\n",
    "\n",
    "[SciPy implementation.](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous_uniform.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Survival function\n",
    "\n",
    "The survival function is essential $1 - \\text{CDF}$, where $CDF$ is the $\\text{cumulative distribution function}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of use\n",
    "\n",
    "A random variable, X, is uniform, a box from 0 to 1 of height 1. (So that its density is $f(x)=1$ for $0≤x≤1$.) What is its median expressed to two decimal places? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform.median(loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Distributions\n",
    "\n",
    "You could broadly describe discrete outcomes as things you can \"count\" - they have finite values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability mass function\n",
    "\n",
    "A probability mass function at a value corresponds to a probability that a random variable takes that value.\n",
    "\n",
    "To be a valid pmf, a function, $p$, must:\n",
    "* Always be $\\geq 0$;\n",
    "* Have the sum of possible variables that the function can take sum to one.\n",
    "\n",
    "Examples of probability mass functions include:\n",
    "* The [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution);\n",
    "* The [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) (used for binary outcomes - the most common example being coin flips).\n",
    "\n",
    "[Wikipedia link](https://en.wikipedia.org/wiki/Probability_mass_function).\n",
    "\n",
    "[SciPy implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_discrete.pmf.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of use\n",
    "A random variable takes the value -4 with probability .2 and 1 with probability .8. What is the variance of this random variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rv_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pmf = rv_discrete(values=((-4, 1), (0.2, 0.8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pmf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pmf.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example\n",
    "Consider the following PMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(range(1,5))\n",
    "example_pmf_2 = rv_discrete(values=(values, values/values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pmf_2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
